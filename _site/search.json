[
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "In the era of digital urbanization, city-wide infrastructures, encompassing transportation modes like buses, taxis, and mass transit, have undergone significant digitization. This transformation has yielded extensive datasets that serve as a fundamental framework for monitoring movement patterns across both space and time. This shift is particularly evident with the widespread adoption of pervasive computing technologies, including GPS and RFID, notably integrated into vehicles. For instance, the utilization of smart cards and GPS devices on public buses enables the collection of comprehensive data on routes and ridership. Within these vast datasets lie inherent structures and patterns that offer valuable insights into the characteristics of measured phenomena, providing a deeper understanding of human movement and behaviors within urban environments. The identification, analysis, and comparison of these patterns present opportunities for enhanced urban management, offering valuable information for both public and private urban transport service providers. Despite these possibilities, current practices often restrict the use of massive locational data to basic tracking and mapping through Geographic Information System (GIS) applications. This limitation arises from the insufficient capabilities of conventional GIS in effectively analyzing and modeling spatial and spatio-temporal data."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#overview",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#overview",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "",
    "text": "In the era of digital urbanization, city-wide infrastructures, encompassing transportation modes like buses, taxis, and mass transit, have undergone significant digitization. This transformation has yielded extensive datasets that serve as a fundamental framework for monitoring movement patterns across both space and time. This shift is particularly evident with the widespread adoption of pervasive computing technologies, including GPS and RFID, notably integrated into vehicles. For instance, the utilization of smart cards and GPS devices on public buses enables the collection of comprehensive data on routes and ridership. Within these vast datasets lie inherent structures and patterns that offer valuable insights into the characteristics of measured phenomena, providing a deeper understanding of human movement and behaviors within urban environments. The identification, analysis, and comparison of these patterns present opportunities for enhanced urban management, offering valuable information for both public and private urban transport service providers. Despite these possibilities, current practices often restrict the use of massive locational data to basic tracking and mapping through Geographic Information System (GIS) applications. This limitation arises from the insufficient capabilities of conventional GIS in effectively analyzing and modeling spatial and spatio-temporal data."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#objective",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#objective",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "Objective",
    "text": "Objective\nIn this study, we first perform\n\nExploratory Spatial Data Analysis (ESDA) to provide us an understanding of the movement patterns on a high level before proceeding to with either\nLocal Indicators of Spatial Association (GLISA)\n\nto undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore in detail."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#task",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#task",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "Task",
    "text": "Task\nThe specific tasks of this take-home exercise are as follows:\n\nGeovisualisation and Analysis\n\nWith reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nDisplay the geographical distribution of the passenger trips by using appropriate geovisualisation methods,\nDescribe the spatial patterns revealed by the geovisualisation (not more than 200 words per visual).\n\n\n\nLocal Indicators of Spatial Association (LISA) Analysis\n\nCompute LISA of the passengers trips generate by origin at hexagon level.\nDisplay the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e.Â p-value &lt; 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 200 words per visual)."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#objective-1",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#objective-1",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "Objective",
    "text": "Objective"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#the-data",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#the-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "The Data",
    "text": "The Data\n\nAspatial data\nFor the purpose of this take-home exercise, Passenger Volume by Origin Destination Bus Stops downloaded from LTA DataMall will be used.\n\n\nGeospatial data\nTwo geospatial data will be used in this study, they are:\n\nBus Stop Location from LTA DataMall. It provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.\nMaster Plan 2019 Planning Sub-zone (No Sea) GIS data set of URA from data.gov.sg"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#install-r-package",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#install-r-package",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "Install R Package",
    "text": "Install R Package\n\npacman::p_load(sf, sfdep, magrittr, tidyverse, tmap, knitr, RColorBrewer, viridis)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#importing-data",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#importing-data",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "1. Importing Data",
    "text": "1. Importing Data\nWe will import the data as a first step before proceeding with data cleaning, data wrangling and data exploration for the following:\n\nPassengerVolume, a csv file,\nBusStop, a point feature layer ESRI shapefile format\n\n\nPassenger VolumeBus Stop Location\n\n\nPassengerVolume is an aspatial data, we can import the data simply by using the read_csv function from tidyverse package and output it as a tibble dataframe called odbus\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202310.csv\")\n\n\n\nBus Stop is a geospatial data in .shp file. We save it as a sf data frame called busstop using the st_read function of the sf package. The data is then geo-referenced to coordinates from the Singapore SVY21 coordinate system (EPSG: 3414)\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs=3414)\n\nReading layer `BusStop' from data source \n  `C:\\weipengten\\ISSS624\\Take-Home_Ex\\Take-Home_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-wrangling",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "2. Data Wrangling",
    "text": "2. Data Wrangling\n\nPassenger VolumeBus Stop LocationHexagonal DatasetCombining the Datasets\n\n\n\nData Exploration\n\nglimpse(odbus)\n\nAs we intend to utilize Bus-stop codes as our unique identifiers when joining with our other datasets, it is not advisable to have it remain as a chr datatype. In fact, we should change it to a factor datatype.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE) \n\n\n\nChecking for Duplicates\nThere is no duplicates\n\nduplicate &lt;- odbus %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\n\n\nChecking for Missing Data\nThere is no missing data\n\nsummary(odbus)\n\n\n\nClassifying Peak Hours\nWith reference to the time intervals provided in the requirements, we computed the passenger trips generated by origin. The passenger trips by origin are saved in 4 dataframes based on their respective classifications namely:\n\nweekday_morning_peak\nweekday_afternoon_peak\nweekend_morning_peak\nweekend_evening_peak\n\n\n\nShow the code\nweekday_morning_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nweekday_afternoon_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nweekend_morning_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\nweekend_evening_peak &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nwrite_rds(weekday_morning_peak, \"data/rds/weekday_morning_peak.rds\")\nweekday_morning_peak &lt;- read_rds(\"data/rds/weekday_morning_peak.rds\")\n\nwrite_rds(weekday_afternoon_peak, \"data/rds/weekday_afternoon_peak.rds\")\nweekday_afternoon_peak &lt;- read_rds(\"data/rds/weekday_afternoon_peak.rds\")\n\nwrite_rds(weekend_morning_peak, \"data/rds/weekend_morning_peak.rds\")\nweekend_morning_peak &lt;- read_rds(\"data/rds/weekend_morning_peak.rds\")\n\nwrite_rds(weekend_evening_peak, \"data/rds/weekend_evening_peak.rds\")\nweekend_evening_peak &lt;- read_rds(\"data/rds/weekend_evening_peak.rds\")\n\n\nIn the code above, we have did a summation of Origin trips , grouped by the origin bus stop number for the 4 classifications through filtering for weekdays from weekends and by the stated time bins.\nWe save our processed data into .rds data format files using theÂ write_rds()Â ofÂ readrÂ package. The output file is saved inÂ rdsÂ sub-folder. We do this to reduce the loading time and more importantly, we can avoid uploading the large raw files onto GitHub.\n\n\n\n\nData is Clean!\nNot surprisingly, there are also no duplicates and missing data for Bus stop Data. The data is clean.\n\nduplicate &lt;- busstop %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\n\nsummary(busstop)\n\n\n\n\n\nCreate Hexagon Dataset from busstop\nNext we proceed to fulfill our requirement of preparing a hexagon dataset with specified cell dimensions of 250 by 250 units called hexagon using the st_make_grid function from the sf package.\nWe convert it into a sf dataframe called hexagon_sf using the st_sf function of sf package.\nThe code also adds a new variable/column called âgrid_idâ to the sf object. The âgrid_idâ values are assigned incrementally, starting from 1 and corresponding to the order of the hexagons in the grid. This step essentially assigns a unique identifier to each hexagon in the grid, facilitating further spatial analysis or mapping.\n\n\nShow the code\nhexagon = st_make_grid(busstop, c(250, 250), what = \"polygons\", square = FALSE)\n\n# To sf and add grid ID\nhexagon_sf = st_sf(hexagon) %&gt;%\n  # add grid ID\n  mutate(grid_id = 1:length(lengths(hexagon)))\n\n\n\n\nExamine The Grid\nA brief overplot shows that there are 22134 grids in total and 19003 are without bus stops. We have a max of 5 bus stops per ORIGIN_GRID.\n\n\nShow the code\nhexagon_sf$n_colli = lengths(st_intersects(hexagon_sf, busstop))\ncount_all_grid_ids &lt;- n_distinct(hexagon_sf$grid_id)\ncount_zero_bus_stops &lt;- hexagon_sf %&gt;%\n  filter(n_colli == 0) %&gt;%\n  summarize(count = n_distinct(grid_id)) %&gt;%\n  pull(count)\nprint(count_all_grid_ids)\n\n\n[1] 22134\n\n\nShow the code\nprint(count_zero_bus_stops)\n\n\n[1] 19003\n\n\nShow the code\nsummary(hexagon_sf$n_colli)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.2332  0.0000  5.0000 \n\n\n\n\nImportant step to ensure this dataset will be useful for us\nFilter for only hexagon data with non-zero counts of bus stops\n\nhexagon_sf = filter(hexagon_sf, n_colli &gt; 0)\nwrite_rds(hexagon_sf, \"data/rds/hexagon_sf.rds\")\nhexagon_sf &lt;- read_rds(\"data/rds/hexagon_sf.rds\")\n\n\n\nVIsualising the dataset\nWe can also do a visualisation to analyze the distribution of busstops. We specify break points at 0,1,2,3,4 and 5\nFrom the map below, it is obvious that most hexagons have 1 or 2 bus stops in their grid with some having 4 or 5 bus stops. There is approximately one âclusterâ that are close to each other and having 4 or 5 bus stops in each region in North, East, South, West.\n\n\nShow the code\ntmap_mode(\"plot\")\n\nmap_busstopcounts = tm_shape(hexagon_sf) +\n  tm_fill(\n    col = \"n_colli\",\n    palette = c(\"grey\",rev(viridis(5))),\n    breaks = c(0, 1, 2, 3, 4, 5),\n    title = \"Number of Busstops\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of collisions: \" = \"n_colli\"\n    ),\n    popup.format = list(\n      n_colli = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)\n\nmap_busstopcounts\n\n\n\n\n\nA few notable findings were:\n\nIn the North-West, bus stops are scarce around the cemetery in Choa Chu Kang, the nearest bus stops in that area are those along Lim Chu Kang road. Tengah Airbase is also located in that area.\nAt the far East, bus stops are scarce around Changi Airport\n- âgrid_idâ = 22027 is an extreme outlier, we will need to drop it\nTowards the middle, we have Paya Lebar Airbase\nIn the middle, we have the Central Water Catchment\nA standalone bus stop in Sentosa Island\n- âgrid_idâ = 11471 is a potential outlier and should be considered for exclusion\nA few bus stops in Johor are surprisingly in our dataset too and in\n- âgrid_idâ = 7068 is an extreme outlier, we will need to drop it.\n- âgrid_idâ for 8113,8237,8351,8485 are potential outliers as well\nOther than those mentioned above, the positioning of the rest of the bus stops seem to be acceptable and will not skew our dataset too much.\n\n\n\nData Cleaning\nHence, letâs proceed straight to dropping these data that will likely cause problems for our analysis. After deeper consideration, we decided that we should drop grid_ids for 22027, 11471 and 7068\n\n\nShow the code\n# Combine Busstop and Hexagon\nhexagon_sf &lt;- hexagon_sf %&gt;%\n  filter(!grid_id %in% c(22027, 11471, 7068))\n\n\n\n\n\nWe needed to perform aggregation of passenger trips by Hexagon instead of Origin Bus Stop, hence we need to first integrate bus stop data and the hexagon dataset using the st_intersection function from the sf package. The intersection operation retains only the spatial elements (points) that overlap between the original bus stop locations and the hexagonal grid.The resulting busstop_hexagon dataset contains information about which hexagon grid each bus stop is located in.\n\n\nShow the code\n# Combine Busstop and Hexagon\nbusstop_hexagon &lt;- st_intersection(busstop, hexagon_sf) %&gt;%\n  select(BUS_STOP_N, grid_id) %&gt;%\n  st_drop_geometry\n\n\nHowever, it is found that there were duplicates:\n- Some bus stops were found to be in multiple grids, this is illogical and should be dropped from analysis.\n-   Example: BUS_STOP 250559 appeared both in grid 4 and 128\n- However it is also found out that are some duplicate entries of bus stops despite showing the same grid_id, this could lead to double counting\n-   Example: BUS_STOP 22501 appeared both with the same grid as 4796\n\n\nShow the code\nduplicate &lt;- busstop_hexagon %&gt;%\n  group_by(BUS_STOP_N) %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\n\n# A tibble: 34 Ã 2\n   BUS_STOP_N grid_id\n   &lt;chr&gt;        &lt;int&gt;\n 1 25059            4\n 2 25059          128\n 3 22501         4796\n 4 22501         4796\n 5 43709         7527\n 6 43709         7527\n 7 47201         9350\n 8 47201         9350\n 9 11009         9625\n10 11009         9625\n# â¹ 24 more rows\n\n\nThus, the following preprocessing steps needs to be done:\n\nfilter out bus stops that have multiple grid_ids\nkeep only unique rows\n\nThe output now shows that we have successful dealt with duplicates and erroneous data from the integration .\n\n\nShow the code\nbusstop_hexagon &lt;- busstop_hexagon %&gt;%\n  group_by(BUS_STOP_N) %&gt;%\n  filter(n_distinct(grid_id)==1) %&gt;%\n  ungroup()\n\nbusstop_hexagon &lt;- busstop_hexagon %&gt;%\n  distinct(BUS_STOP_N , grid_id, .keep_all = TRUE )\n\nduplicate &lt;- busstop_hexagon %&gt;%\n  group_by(BUS_STOP_N) %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\n\n# A tibble: 0 Ã 2\n# â¹ 2 variables: BUS_STOP_N &lt;chr&gt;, grid_id &lt;int&gt;\n\n\nNext, we sum up the total passenger trips group by each hexagon grid as ORIGIN_GRID for the 4 dataframes seperately to get the resulting tibble dataframes.\n\nweekday_morning_peak_join_list &lt;- left_join(weekday_morning_peak , busstop_hexagon,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE, ORIGIN_GRID = grid_id) %&gt;%\n  group_by(ORIGIN_GRID) %&gt;%\n  summarise(TOT_TRIPS = sum(TRIPS))\n\n\n\nweekday_afternoon_peak_join_list &lt;- left_join(weekday_afternoon_peak , busstop_hexagon,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE, ORIGIN_GRID = grid_id) %&gt;%\n  group_by(ORIGIN_GRID) %&gt;%\n  summarise(TOT_TRIPS = sum(TRIPS))\n\n\n\nweekend_morning_peak_join_list &lt;- left_join(weekend_morning_peak , busstop_hexagon,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE, ORIGIN_GRID = grid_id) %&gt;%\n  group_by(ORIGIN_GRID) %&gt;%\n  summarise(TOT_TRIPS = sum(TRIPS))\n\n\n\nweekend_evening_peak_join_list &lt;- left_join(weekend_evening_peak , busstop_hexagon,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE, ORIGIN_GRID = grid_id) %&gt;%\n  group_by(ORIGIN_GRID) %&gt;%\n  summarise(TOT_TRIPS = sum(TRIPS))\n\nAfter that is done, we have to join back with our sf dataset using grid_id.\nThis code chunk below performs several operations to analyze the total number of trips (TOT_TRIPS) during weekday morning peak hours based on the origin bus stop and its corresponding hexagonal grid instead of its previous bus stop number we are using.\n\n\nShow the code\nweekday_morning_peak_join_geometry &lt;- left_join(hexagon_sf, \n                           weekday_morning_peak_join_list,\n                           by = c(\"grid_id\" = \"ORIGIN_GRID\"))\n\nweekday_afternoon_peak_join_geometry &lt;- left_join(hexagon_sf, \n                           weekday_afternoon_peak_join_list,\n                           by = c(\"grid_id\" = \"ORIGIN_GRID\"))\n\nweekend_morning_peak_join_geometry &lt;- left_join(hexagon_sf, \n                           weekend_morning_peak_join_list,\n                           by = c(\"grid_id\" = \"ORIGIN_GRID\"))\n\nweekend_evening_peak_join_geometry &lt;- left_join(hexagon_sf, \n                           weekend_evening_peak_join_list,\n                           by = c(\"grid_id\" = \"ORIGIN_GRID\"))\n\nwrite_rds(weekday_morning_peak_join_geometry, \"data/rds/weekday_morning_peak_join_geometry.rds\")\nweekday_morning_peak_join_geometry &lt;- read_rds(\"data/rds/weekday_morning_peak_join_geometry.rds\")\n\nwrite_rds(weekday_afternoon_peak_join_geometry, \"data/rds/weekday_afternoon_peak_join_geometry.rds\")\nweekday_afternoon_peak_join_geometry &lt;- read_rds(\"data/rds/weekday_afternoon_peak_join_geometry.rds\")\n\nwrite_rds(weekend_morning_peak_join_geometry, \"data/rds/weekend_morning_peak_join_geometry.rds\")\nweekend_morning_peak &lt;- read_rds(\"data/rds/weekend_morning_peak.rds\")\n\nwrite_rds(weekend_evening_peak_join_geometry, \"data/rds/weekend_evening_peak_join_geometry.rds\")\nweekend_evening_peak_join_geometry &lt;- read_rds(\"data/rds/weekend_evening_peak_join_geometry.rds\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#exploratory-data-analysis-eda",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#exploratory-data-analysis-eda",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "3. Exploratory Data Analysis (EDA)",
    "text": "3. Exploratory Data Analysis (EDA)\n\nDistribution of Total TripsDistribution for Total Trips PER Bus StopDistribution for Total Trips Across 4 PeriodsDistribution for Total Trips PER Bus Stop Across 4 Periods\n\n\nWe discovered that the data has a right-tailed distribution for all time classifications.\n\n\nShow the code\ncombined_data &lt;- rbind(\n  transform(weekday_morning_peak_join_geometry, period = \"Weekday Morning Peak\"),\n  transform(weekday_afternoon_peak_join_geometry, period = \"Weekday Afternoon Peak\"),\n  transform(weekend_morning_peak_join_geometry, period = \"Weekend Morning Peak\"),\n  transform(weekend_evening_peak_join_geometry, period = \"Weekend Evening Peak\")\n)\n\n# Plot combined data\nggplot(data = combined_data, \n       aes(x = as.numeric(`TOT_TRIPS`))) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\") +\n  facet_wrap(~period, scales = \"free_y\") +\n  labs(title = \"Distribution of Passenger Trips during Different Time Periods\",\n       subtitle = \"Histograms show the distribution of total trips for different time periods\",\n       x = \"Total Trips\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\nSimilarly, for trips per bus stopâ¦\n\n\nShow the code\ncombined_density &lt;- combined_data %&gt;%\n  mutate(`trips_per_busstop` = (`TOT_TRIPS` / n_colli))\n\n\n# Plot combined data\nggplot(data = combined_density, \n       aes(x = as.numeric(`trips_per_busstop`))) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = \"light blue\") +\n  facet_wrap(~period, scales = \"free_y\") +\n  labs(title = \"Distribution of Passenger Trips during Different Time Periods\",\n       subtitle = \"Histograms show the distribution of total trips for different time periods\",\n       x = \"Total Trips Per BusStop\",\n       y = \"Frequency\")\n\n\n\n\n\n\n\nA quick examination of the distribution of origin trips across all four periods reveals that the weekday morning peak has the highest number of trip counts, followed by the weekday afternoon peak, the weekend morning peak, and finally, the weekend evening peak.\nThis observation suggests that, during the specified time periods, there is a discernible pattern in the frequency of trips, with a notable concentration of trips during weekday mornings. This information could imply potential trends in commuting behavior or specific usage patterns during different times of the week.\nTransport agencies can allocate resources such as personnel and busses better with this information. Frequency of busses should also be increased for weekday afternoon peak period.\n\n\nShow the code\nggplot(combined_data, aes(x = factor(period), y = TOT_TRIPS, fill = factor(period))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Counts of Total Trips Grouped by Periods\",\n       x = \"Period\",\n       y = \"TOT_TRIPS Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\nTrips per bus stop turns out to demonstrate similar patterns as compared to total trips.\nThis actually suggest that the transport authorities have done well in the planning of decision of bus stop locations over the years.\nPerhaps this also mean that it is safe to analyse the choropleths using total trips by itself later on.\n\n\nShow the code\nggplot(combined_density, aes(x = factor(period), y = trips_per_busstop, fill = factor(period))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Counts of Trips Per Bus Stop Grouped by Periods\",\n       x = \"Period\",\n       y = \"Trips Per Bus Stop\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#geovisualisation-and-analysis-1",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#geovisualisation-and-analysis-1",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "4. Geovisualisation and Analysis",
    "text": "4. Geovisualisation and Analysis\n\nImportant Considerations\n\nDue to the use of small hexagon tiles and a heavily right skewed distribution, quantile classification proves to provide little value. We decided that kmeans classification is best due to the ability to create discrete classes. This helps us to compare the 4 periods easily.\nWe previously derived number of Passenger Trips using the bus stops as the origin. This means that that some tiles could have missing data due to the lack of trips originating from there but that not necessary be the case for trips with that as the destination.\nWe previously excluded tiles with no bus stops earlier in hexagon_sf, hence any missing data present here is not due to missing bus stops\n\n\n\nGeneral Observations across all 4 interval classifications\n\nThe bus stops along Lim Chu Kang exhibit minimal to no origin trips on both weekdays and weekends. This can be attributed to the presence of a cemetery in that area, making it more practical for individuals to use private transportation.\nAdditionally, along the eastern coast, there are several bus stops without origin trips on weekdays. However, the situation changes on weekends and holidays, although the overall volume remains low. It is advisable to consider adjusting the bus schedule in that region for weekdays. A similar pattern is observed for the islands in the North-West..\nOrigin Trips for a few bus stops near the customs remain high through weekdays and wekends. Also, one bus stop in Johor is consistently high in origin trips.\nIn central areas, origin trips are not high during weekday mornings but are high during weekday afternoons. This is probably due to residential planning by the URA where residents travel from the other regions to the central and business districts.\n\n\nWeekday Morning PeakWeekday Afternoon PeakWeekend/holiday Morning PeakWeekend/holiday Evening Peak\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\ninferno_palette &lt;- inferno(5)\ntmap_options(check.and.fix = TRUE)\ntm_shape(weekday_morning_peak_join_geometry)+\n  tm_fill(\"TOT_TRIPS\", \n          style = \"kmeans\", \n          palette = viridis(5),\n          title = \"Passenger trips\") +\n  tm_layout(main.title = \"Passenger trips during Weekday morning peak\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)+\n  tmap_style(\"natural\")\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\ntmap_options(check.and.fix = TRUE)\ntm_shape(weekday_afternoon_peak_join_geometry)+\n  tm_fill(\"TOT_TRIPS\", \n          style = \"kmeans\", \n          palette = viridis(5),\n          title = \"Passenger trips\") +\n  tm_layout(main.title = \"Passenger trips during Weekday afternoon peak\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)+\n  tmap_style(\"natural\")\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\ntmap_options(check.and.fix = TRUE)\ntm_shape(weekend_morning_peak_join_geometry)+\n  tm_fill(\"TOT_TRIPS\", \n          style = \"kmeans\", \n          palette = viridis(5),\n          title = \"Passenger trips\") +\n  tm_layout(main.title = \"Passenger trips during Weekend/holiday morning peak\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)+\n  tmap_style(\"natural\")\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\ntmap_options(check.and.fix = TRUE)\ntm_shape(weekend_evening_peak_join_geometry)+\n  tm_fill(\"TOT_TRIPS\", \n          style = \"kmeans\",\n          palette = viridis(5), \n          title = \"Passenger trips\") +\n  tm_layout(main.title = \"Passenger trips during Weekend/holiday evening peak\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tmap_style(\"natural\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#local-indicators-of-spatial-association-lisa-analysis-1",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#local-indicators-of-spatial-association-lisa-analysis-1",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "5. Local Indicators of Spatial Association (LISA) Analysis",
    "text": "5. Local Indicators of Spatial Association (LISA) Analysis\nLocal Indicators of Spatial Association (LISA) Analysis:\nLocal Indicators of Spatial Association (LISA) is a statistical technique used in spatial analysis to identify and assess spatial patterns of clustering or dispersion within a geographical dataset. LISA analysis helps to uncover local patterns of spatial autocorrelation, providing insights into whether similar values tend to cluster together or if there are areas with dissimilar values.\nLISA analysis is based on the concept of spatial autocorrelation, which measures the degree to which neighboring locations are similar or dissimilar in terms of a particular variable. (In Our case, it is Origin Passenger Trips)\nTwo key LISA statistics are Moranâs I and the associated p-value, for each spatial unit (hexagon grid in our case) to determine if they are part of a significant cluster, outlier, or exhibit no significant pattern.\nLocal Moranâs I identifies clusters by categorizing each unit as High-High (high value surrounded by high values), Low-Low (low value surrounded by low values), High-Low (high value surrounded by low values), or Low-High (low value surrounded by high values).\n- Decision-making process\nDue to the use of hexagon grids, we had many empty grids and this proves difficult to derive contiguity weights. Hence, we attempted to derive distance weights instead\nFixed distance weight matrix was used in deriving the weights and neighbors.\n\n5.1 Deriving adaptive distance weights\nThe summary statistics report below shows that the maximum nearest neighbour distance is 901.4m. By using a threshold value of 902m will ensure that each area will have at least one neighbour.\n\n\nShow the code\ngeo &lt;- sf::st_geometry(hexagon_sf)\nnb &lt;- st_knn(geo, longlat = TRUE)\ndists &lt;- unlist(st_nb_dists(geo, nb))\nsummary(dists)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  250.0   250.0   250.0   257.5   250.0   901.4 \n\n\nNow we will go ahead to compute the fixed distance weights by using the code chunk below.\nThe use of .allow_zero = TRUE option is to assign the value of 0 to rows with missing values for TOT_TRIPS as missing values will create problems for our analysis later\n\n\nShow the code\nwm_q_1 &lt;- weekday_morning_peak_join_geometry %&gt;%\n  mutate(TOT_TRIPS = replace_na(TOT_TRIPS, 0), \n         nb = st_dist_band(hexagon,\n                           upper = 902),\n         wt = st_weights(nb,\n                         style = \"W\",\n                         allow_zero = TRUE),\n         .before = 1) \n\n\nwm_q_2 &lt;- weekday_afternoon_peak_join_geometry %&gt;%\n  mutate(TOT_TRIPS = replace_na(TOT_TRIPS, 0),  \n         nb = st_dist_band(hexagon,\n                           upper = 902),\n         wt = st_weights(nb,\n                         style = \"W\",\n                         allow_zero = TRUE),\n         .before = 1) \n\nwm_q_3 &lt;- weekend_morning_peak_join_geometry %&gt;%\n  mutate(TOT_TRIPS = replace_na(TOT_TRIPS, 0),  \n         nb = st_dist_band(hexagon,\n                           upper = 902),\n         wt = st_weights(nb,\n                         style = \"W\",\n                         allow_zero = TRUE),\n         .before = 1) \n\n\nwm_q_4 &lt;- weekend_evening_peak_join_geometry %&gt;%\n  mutate(TOT_TRIPS = replace_na(TOT_TRIPS, 0),  \n         nb = st_dist_band(hexagon,\n                           upper = 902),\n         wt = st_weights(nb,\n                         style = \"W\",\n                         allow_zero = TRUE),\n         .before = 1) \n\n\n\n\n5.2 Computing local Moranâs I\nIn this section, we will compute Local Moranâs I of Total Passenger Trips at county level by using local_moran() of sfdep package.\nThe provided code conducts a Local Moranâs I analysis on four distinct datasets (wm_q_1, wm_q_2, wm_q_3, wm_q_4), each associated with specific time periods or scenarios.\nThe analysis focuses on the spatial autocorrelation of the variable TOT_TRIPS within each dataset, employing the local_moran function with\n\nneighbors (nb) and\nweights (wt) and\n99 simulations.\n\nThe calculated Local Moranâs I statistic assesses whether nearby observations exhibit similar total trip values, revealing spatial patterns and clusters.\nThe use of unnest implies a need to extract detailed information about the spatial relationships between observations and their neighbors after the Local Moranâs I analysis.\n\n\nShow the code\nlisa_1 &lt;- wm_q_1 %&gt;% \n  mutate(local_moran = local_moran(\n    TOT_TRIPS, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\nlisa_2 &lt;- wm_q_2 %&gt;% \n  mutate(local_moran = local_moran(\n    TOT_TRIPS, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\nlisa_3 &lt;- wm_q_3 %&gt;% \n  mutate(local_moran = local_moran(\n    TOT_TRIPS, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\nlisa_4 &lt;- wm_q_4 %&gt;% \n  mutate(local_moran = local_moran(\n    TOT_TRIPS, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n\n\n\n5.3 Visualising local Moranâs I\nIn the following code section, tmap functions are utilized to create a choropleth map based on the values in the ii field, representing the Local Moranâs I values. The chosen tmap_style option is set to albatross to suit the gridâs nature and emphasize clusters, where lighter colors indicate positive values and darker colors indicate negative values.\nItâs important to note that a positive Local Moranâs I value signifies a featureâs membership in a cluster, while a negative value suggests that a feature is an outlier.\nExamining the map, regions shaded in various hues of green indicate their membership in one or more clusters.While there are overlapping areas among the maps generated for the four periods of interest, there are also discrepancies.\nHowever, relying solely on the local Moranâs score is insufficient for depicting spatial clustering, as it doesnât provide information about whether the variableâs value (Total Passenger Trips) being examined is high or low, and whether the test result is statistically significant. We need to proceed with analyzing only the regions with statistically significant values of total passenger trips.\n\n5.3.1 Weekday Morning Peak5.3.2 Weekday Afternoon Peak5.3.3 Weekend Morning Peak5.3.4 Weekend Afternoon Peak\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(lisa_1) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(5)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekday morning\",\n            main.title.size = 0.8) +\n  tmap_style(\"albatross\")\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(lisa_2) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(5)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekday afternoon\",\n            main.title.size = 0.8) +\n  tmap_style(\"albatross\")\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(lisa_3) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(5)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekend morning\",\n            main.title.size = 0.8) +\n  tmap_style(\"albatross\")\n\n\n\n\n\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(lisa_4) +\n  tm_fill(\"ii\",\n          style = \"kmeans\",\n         palette = viridis(5)) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"local Moran I of Bus Trips in weekend afternoon\",\n            main.title.size = 0.8) +\n  tmap_style(\"albatross\")\n\n\n\n\n\n\n\n\n\n\n5.4 Visualising p-value of local Moranâs I\nIn the code chunk below, tmap functions are used to prepare a choropleth map by using value in the p_ii_sim field\nWe will visualize solely the statistically significant local Moranâs I values (p_ii_sim &lt; 0.05) through the subsequent code snippet.\n\n5.4.1 Weekday Morning Peak5.4.2 Weekday Afternoon Peak5.4.3 Weekend Morning Peak5.4.4 Weekend Afternoon Peak\n\n\nComparing local Moranâs I together with its p_ii_sim values, a few observations were revealed:\n\nThere are clusters near customs and throughout most of west area. They are all statistically significant.\nClusters and dispersions found in the South / Central are mostly not statistically significant and should be ignored.\nThere are both many clusters and dispersions found in Bedok, Tampines, Pasir Ris and Changi that are found to be statistically significant. However, not so much for other parts of East.\nClusters and Dispersions found in North east and North are also statistically significant.\n\nThese Clusters found seem to match our expectations as they are within residential zones. However, this is possible also because of bus interchanges and the wider options of buses avaliable near these bus interchanges.\nWhat about the dispersion that we are observing? It is easy to dismiss that. However they tend to happen around those clusters found. This can actually be explained with the fact that are OTHER options other than taking buses such as a little bit of walk orâ¦. Cycling!!! as a form of commuting.\nThis trend may not be immediately apparent to individuals who donât utilize public transportation or to foreigners. However, itâs becoming increasingly common for Singaporeans to use personal transport, such as bicycles, to reach bus interchanges instead of waiting for buses directly at their residences. This choice is driven by the realization that cycling to the bus interchange can be a more time-efficient option. The areas surrounding bus interchanges often face congestion with numerous bus stops and traffic lights, turning what should be a short journey into a lengthy one.\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(lisa_1) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(5)), \"grey\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran I in weekday morning\",\n            main.title.size = 0.8) +\n  tmap_style(\"watercolor\")\n\n\n\n\n\n\n\nThere are few dispersions this time round and more clusters found instead.\nMost of previously residential areas identified are found to not display any statistically significant patterns, other than some parts around tampines and north east which could be hubs designated by the government.\nMany statistically significant clusters are found around west region which is also an industrial region.\nCentral business district areas do not exhibit any significant patterns, it seems most office workers do not take buses home but the MRT instead.\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(lisa_2) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(5)), \"grey\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran I in weekday afternoon\",\n            main.title.size = 0.8) +\n  tmap_style(\"watercolor\")\n\n\n\n\n\n\n\nIt seems there are more dispersions during mornings peak hours even for weekends/holidays.\nThere are less clusters as compared to weekdays. The most significant clusters are those found around Bugis and Lavender.\nClusters found near NUS are statistically significant, it is unsure if it is due to the school itself.\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(lisa_3) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(5)), \"grey\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran I in weekend morning\",\n            main.title.size = 0.8) +\n  tmap_style(\"watercolor\")\n\n\n\n\n\n\n\nThere are very few dispersions this time round, with three in Johor, this is not surprising as any Singapore would understand that most wonât choose that time to travel back to Singapore and this data only record trips between Singapore bus stops and does not include trips not under SBS.\nMore clusters are shown and are quite concentrated as compared to weekdays.\n\n\nShow the code\ntmap_mode(\"plot\")\ntm_shape(lisa_4) +\n  tm_fill(\"p_ii_sim\",\n          palette = c(rev(viridis(5)), \"grey\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran I in weekend afternoon\",\n            main.title.size = 0.8) +\n  tmap_style(\"watercolor\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "This in-class introduces an alternative R package to spdep package you used in Hands-on Exercise 6. The package is called sfdep. According to Josiah Parry, the developer of the package, âsfdep builds on the great shoulders of spdep package for spatial dependence. sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. sfdep utilizes list columns extensively to make this interface possible.â"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#overview",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#overview",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "This in-class introduces an alternative R package to spdep package you used in Hands-on Exercise 6. The package is called sfdep. According to Josiah Parry, the developer of the package, âsfdep builds on the great shoulders of spdep package for spatial dependence. sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. sfdep utilizes list columns extensively to make this interface possible.â"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#getting-started",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#getting-started",
    "title": "In-class Exercise 3",
    "section": "Getting started",
    "text": "Getting started\n\npacman::p_load(tmap, sf, sp, DT,\n               performance, reshape2,\n               ggpubr, units, tidyverse)\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\weipengten\\ISSS624\\In-class_Ex\\In-class_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz_sp &lt;- as(mpsz, \"Spatial\")\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR \n\n\n\ndist &lt;- spDists(mpsz_sp, \n                longlat = FALSE)\nhead(dist, n=c(10, 10))\n\n           [,1]       [,2]      [,3]      [,4]       [,5]      [,6]      [,7]\n [1,]     0.000  3926.0025  3939.108 20252.964  2989.9839  1431.330 19211.836\n [2,]  3926.003     0.0000   305.737 16513.865   951.8314  5254.066 16242.523\n [3,]  3939.108   305.7370     0.000 16412.062  1045.9088  5299.849 16026.146\n [4,] 20252.964 16513.8648 16412.062     0.000 17450.3044 21665.795  7229.017\n [5,]  2989.984   951.8314  1045.909 17450.304     0.0000  4303.232 17020.916\n [6,]  1431.330  5254.0664  5299.849 21665.795  4303.2323     0.000 20617.082\n [7,] 19211.836 16242.5230 16026.146  7229.017 17020.9161 20617.082     0.000\n [8,] 14960.942 12749.4101 12477.871 11284.279 13336.0421 16281.453  5606.082\n [9,]  7515.256  7934.8082  7649.776 18427.503  7801.6163  8403.896 14810.930\n[10,]  6391.342  4975.0021  4669.295 15469.566  5226.8731  7707.091 13111.391\n           [,8]      [,9]     [,10]\n [1,] 14960.942  7515.256  6391.342\n [2,] 12749.410  7934.808  4975.002\n [3,] 12477.871  7649.776  4669.295\n [4,] 11284.279 18427.503 15469.566\n [5,] 13336.042  7801.616  5226.873\n [6,] 16281.453  8403.896  7707.091\n [7,]  5606.082 14810.930 13111.391\n [8,]     0.000  9472.024  8575.490\n [9,]  9472.024     0.000  3780.800\n[10,]  8575.490  3780.800     0.000\n\n\n\n16.5.3 Labelling column and row heanders of a distance matrix\n\nsz_names &lt;- mpsz$SUBZONE_C\ncolnames(dist) &lt;- paste0(sz_names)\nrownames(dist) &lt;- paste0(sz_names)\n\n\ndistPair &lt;- melt(dist) %&gt;%\n  rename(dist = value)\nhead(distPair, 10)\n\n     Var1   Var2      dist\n1  MESZ01 MESZ01     0.000\n2  RVSZ05 MESZ01  3926.003\n3  SRSZ01 MESZ01  3939.108\n4  WISZ01 MESZ01 20252.964\n5  MUSZ02 MESZ01  2989.984\n6  MPSZ05 MESZ01  1431.330\n7  WISZ03 MESZ01 19211.836\n8  WISZ02 MESZ01 14960.942\n9  SISZ02 MESZ01  7515.256\n10 SISZ01 MESZ01  6391.342\n\n\n\n\n16.5.5 Updating intra-zonal distances\nIn this section, we are going to append a constant value to replace the intra-zonal distance of 0.\nFirst, we will select and find out the minimum value of the distance by using summary().\n\ndistPair %&gt;%\n  filter(dist &gt; 0) %&gt;%\n  summary()\n\n      Var1             Var2             dist        \n MESZ01 :   331   MESZ01 :   331   Min.   :  173.8  \n RVSZ05 :   331   RVSZ05 :   331   1st Qu.: 7149.5  \n SRSZ01 :   331   SRSZ01 :   331   Median :11890.0  \n WISZ01 :   331   WISZ01 :   331   Mean   :12229.4  \n MUSZ02 :   331   MUSZ02 :   331   3rd Qu.:16401.7  \n MPSZ05 :   331   MPSZ05 :   331   Max.   :49894.4  \n (Other):107906   (Other):107906                    \n\n\nNext, a constant distance value of 50m is added into intra-zones distance. &gt; 50 is derived from approximately minimum of 173.8 (found out earlier in summary statistics) divided by 2. Note : *Intra-zone\n\ndistPair$dist &lt;- ifelse(distPair$dist == 0,\n                        50, distPair$dist)\ndistPair %&gt;%\n  summary()\n\n      Var1             Var2             dist      \n MESZ01 :   332   MESZ01 :   332   Min.   :   50  \n RVSZ05 :   332   RVSZ05 :   332   1st Qu.: 7097  \n SRSZ01 :   332   SRSZ01 :   332   Median :11864  \n WISZ01 :   332   WISZ01 :   332   Mean   :12193  \n MUSZ02 :   332   MUSZ02 :   332   3rd Qu.:16388  \n MPSZ05 :   332   MPSZ05 :   332   Max.   :49894  \n (Other):108232   (Other):108232                  \n\n\n\ndistPair &lt;- distPair %&gt;%\n  rename(orig = Var1,\n         dest = Var2)\n\nwrite_rds(distPair, \"data/rds/distPair.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#preparing-flow-data",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#preparing-flow-data",
    "title": "In-class Exercise 3",
    "section": "16.6 Preparing flow data",
    "text": "16.6 Preparing flow data\n\nod_data &lt;- read_rds(\"data/rds/od_data.rds\")\n\nflow_data &lt;- od_data %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;% \n  summarize(TRIPS = sum(MORNING_PEAK)) \n\nhead(flow_data, 10)\n\n# A tibble: 10 Ã 3\n# Groups:   ORIGIN_SZ [1]\n   ORIGIN_SZ DESTIN_SZ TRIPS\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n 1 AMSZ01    AMSZ01     2694\n 2 AMSZ01    AMSZ02    10591\n 3 AMSZ01    AMSZ03    14980\n 4 AMSZ01    AMSZ04     3106\n 5 AMSZ01    AMSZ05     7734\n 6 AMSZ01    AMSZ06     2306\n 7 AMSZ01    AMSZ07     1824\n 8 AMSZ01    AMSZ08     2734\n 9 AMSZ01    AMSZ09     2300\n10 AMSZ01    AMSZ10      164\n\n\n\n16.6.1 Separating intra-flow from passenger volume df\n\nflow_data$FlowNoIntra &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0, flow_data$TRIPS)\nflow_data$offset &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0.000001, 1)\n\n\n\n16.6.2 Combining passenger volume data with distance value\nBefore we can join flow_data and distPair, we need to convert data value type of ORIGIN_SZ and DESTIN_SZ fields of flow_data dataframe into factor data type.\n\nflow_data$ORIGIN_SZ &lt;- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ &lt;- as.factor(flow_data$DESTIN_SZ)\n\nNow, left_join() of dplyr will be used to merge flow_data dataframe and distPair dataframe. The output is called flow_data1.\n\nflow_data1 &lt;- flow_data %&gt;%\n  left_join (distPair,\n             by = c(\"ORIGIN_SZ\" = \"orig\",\n                    \"DESTIN_SZ\" = \"dest\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#preparing-origin-and-destination-attributes",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#preparing-origin-and-destination-attributes",
    "title": "In-class Exercise 3",
    "section": "16.7 Preparing Origin and Destination Attributes",
    "text": "16.7 Preparing Origin and Destination Attributes\n\n16.7.1 Importing population data\n\npop &lt;- read_csv(\"data/aspatial/pop.csv\")\n\n###v16.7.2 Geospatial data wrangling\n\npop &lt;- pop %&gt;%\n  left_join(mpsz,\n            by = c(\"PA\" = \"PLN_AREA_N\",\n                   \"SZ\" = \"SUBZONE_N\")) %&gt;%\n  select(1:6) %&gt;%\n  rename(SZ_NAME = SZ,\n         SZ = SUBZONE_C)\n\n\n\n16.7.3 Preparing origin attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(ORIGIN_SZ = \"SZ\")) %&gt;%\n  rename(ORIGIN_AGE7_12 = AGE7_12,\n         ORIGIN_AGE13_24 = AGE13_24,\n         ORIGIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\n\n\n16.7.4 Preparing destination attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(DESTIN_SZ = \"SZ\")) %&gt;%\n  rename(DESTIN_AGE7_12 = AGE7_12,\n         DESTIN_AGE13_24 = AGE13_24,\n         DESTIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\nWe will called the output data file SIM_data. it is in rds data file format.\nwrite_rds(flow_data1, âchap16/data/rds/SIM_dataâ)\n16.8 Calibrating Spatial Interaction Models In this section, you will learn how to calibrate Spatial Interaction Models by using Poisson Regression method.\n16.8.1 Importing the modelling data Firstly, let us import the modelling data by using the code chunk below.\nSIM_data &lt;- read_rds(âchap16/data/rds/SIM_data.rdsâ)\n16.8.2 Visualising the dependent variable Firstly, let us plot the distribution of the dependent variable (i.e.Â TRIPS) by using histogram method by using the code chunk below.\nggplot(data = SIM_data, aes(x = TRIPS)) + geom_histogram()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#visualising-lisa-map",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#visualising-lisa-map",
    "title": "Take Home Exercise 1 - Geospatial Analytics for Public Good",
    "section": "6 Visualising LISA map",
    "text": "6 Visualising LISA map\nIn this visualisation, LISA categorises each region into one of four groups:\n\nHigh-High indicates grids with high number of origin trips located next to other grids with high number of origin trips\nLow-High indicates grids with low number of origin trips located next to other grids with high number of origin trips\nHigh-Low indicates grids with high number of origin trips located next to other grids with low number of origin trips\nLow-Low indicates grids with low number of origin trips located next to other grids with low number of origin trips\n\n\n6.1 Weekday Morning Peak6.2 Weekday Afternoon Peak6.3 Weekend Morning Peak6.4 Weekend Afternoon Peak\n\n\nIn this visualisation for Weekday Morning Peak, some observations were found:\n\nHigh-High regions were found throughout parts of North-East, North-West, Central and West, except South. These spots also seem to be nearby each other in their respective regions, seemingly signifying hubs.\nLow-High regions are few in existence and happened to be near High-High regions\nHigh-Low regions are almost none.\nLow-Low regions happened to be found near the borders of Singapore mostly. They coincide with non-residential areas like changi airport Tuas and near cemetries.\n\n\n\nShow the code\ntmap_mode(\"plot\")\nlisa_sig &lt;- lisa_1  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_1) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(5))) + \n  tm_borders(alpha = 0.4)+\n  tmap_style(\"albatross\")\n\n\n\n\n\n\n\nHigh-High and High-Low regions are few here and definitely much less than during Weekday Morning Peak.\nThere are three clusters of High-High regions (Jurong west, Woodlands, Bedok), with some Low-High regions around..\nLow-Low regions are found in Tuas Industrial are and throughout parts of Singapore\nMost Residential areas show no patterns.\n\n\nShow the code\ntmap_mode(\"plot\")\nlisa_sig &lt;- lisa_2  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_2) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(5))) + \n  tm_borders(alpha = 0.4) +\n  tmap_style(\"albatross\")\n\n\n\n\n\n\n\nMore High-High clusters are found with the previous three High-High clusters remaining strong for (Jurong west, Woodlands, Tampines). In addition to those three, are additional clusters found around Ang Mo Kio, Toa Payoh, Bedok and Bugis.\nLow-Low areas are found near Tuas and Changi Airport again and the stretch along cemeteries in Lim Chu Kang\n\n\nShow the code\ntmap_mode(\"plot\")\nlisa_sig &lt;- lisa_3  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_3) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(5))) + \n  tm_borders(alpha = 0.4) +\n  tmap_style(\"albatross\")\n\n\n\n\n\n\n\nThe patterns for this section seems almost similar to Weekend Morning Peak, most clusters remain but shows less activity compared to its morning.\n\n\nShow the code\ntmap_mode(\"plot\")\nlisa_sig &lt;- lisa_4  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_4) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"median\",\n          palette = c(viridis(5))) + \n  tm_borders(alpha = 0.4) +\n  tmap_style(\"albatross\")"
  }
]